# Proyecto 2: Limpieza y procesamiento de datos

## üìù Descripci√≥n
Este proyecto consiste en un an√°lisis profundo y tratamiento de un conjunto de datos de Lending Club, una empresa de pr√©stamos en EE. UU.. El objetivo principal es realizar la limpieza, preprocesado y reducci√≥n de dimensionalidad de datos hist√≥ricos de pr√©stamos (2007-2015) para preparar el dataset para futuros modelos predictivos de riesgo crediticio o estado de pr√©stamos.

## üõ†Ô∏è Herramientas y Tecnolog√≠as
‚Ä¢‚Å† ‚Å†Lenguaje: Python 3.x 
‚Ä¢ Librer√≠as: Pandas, NumPy, Seaborn, Matplotlib, Scikit-Learn. 
‚Ä¢ T√©cnicas Aplicadas: * An√°lisis Exploratorio de Datos (EDA) y correlaciones. * Imputaci√≥n de valores faltantes (SimpleImputer). * Escalado de variables (StandardScaler). * Codificaci√≥n de variables categ√≥ricas (LabelEncoder, OneHotEncoder). * Reducci√≥n de dimensionalidad (PCA).

## üìä Dashboard / Resultados
‚Ä¢‚Å†  ‚Å†Varianza Explicada: Mediante el an√°lisis de Componentes Principales (PCA), se determin√≥ que los dos primeros componentes explican aproximadamente el 98% de la varianza total de los datos (87% el primero y 11% el segundo). 
‚Ä¢ Reducci√≥n √ìptima: El m√©todo del "codo" sugiri√≥ que el uso de dos componentes es suficiente para representar la mayor parte de la variabilidad original sin p√©rdida significativa de informaci√≥n. 
‚Ä¢ Calidad de Datos: Se realiz√≥ un tratamiento exhaustivo de outliers y multicolinealidad para asegurar la estabilidad de futuros modelos.
